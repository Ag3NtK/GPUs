Parte A — Inspección estática con nvidia-smi

Modelo exacto de GPU. ----> NVIDIA GeForce RTX 3070 Laptop GPU
Memoria total y memoria actualmente en uso. ----> 755MiB / 8192MiB
Versión del driver NVIDIA. ----> 591.59 
Estado de utilización (GPU utilization) y consumo/potencia. ----> GPU utilization = 1%       Consumo / potencia = 25W / 140W



# Informe Laboratorio 1: Caracterización Experimental de la GPU
**Asignatura:** Programación en GPUs
**Nombre:** Javier [Tu Apellido]
**Fecha:** 16 de Febrero de 2026

---

## 1. Ejercicio 1 — Exploración y caracterización del dispositivo

### 1.1. Parte A — Inspección estática con `nvidia-smi`

Datos extraídos del comando base:
* **Modelo de GPU:** [NVIDIA GeForce RTX 3070 Laptop GPU]
* **Memoria Uso / Total:** [755MiB / 8192MiB]
* **Versión del Driver:** [591.59]
* **Utilización de GPU:** [1%]
* **Potencia (Draw/Cap):** [25W/140W]

#### Cuestiones Parte A
1. **¿La memoria es RAM o dedicada?** Es memoria VRAM dedicada de la GPU. La RAM del sistema se gestiona por la CPU y es independiente.
2. **¿Qué es GPU utilization?** Es el % de tiempo del último segundo en que hubo kernels activos. Puede ser baja con memoria llena si los datos están cargados pero no se están procesando (Memory bound).
3. **¿Por qué se muestra la potencia?** Para poder ver y controlar el límite térmico y energético (TDP). Es vital para evitar que el hardware se dañe y para dimensionar la fuente.

### Parte A.2 — Inspección detallada (`nvidia-smi -q`)
* **Capacidad y tipo de memoria:** [8192MiB: GDDR6]
* **Clocks Máximos:** [Graphics: 2100 MHz, SM: 2100 MHz, Memory: 7001 MHz, Video: 1950 MHz]
* **Enlace PCIe:** [Max: Gen 4 x16, Current: Gen 2 x16]

---

### 1.2. Parte B — Observación dinámica (`busy.cu`)

[Image of nvidia-smi output table showing GPU load and power increase]

| Campo | Idle | Ejecutando `busy` |
| :--- | :--- | :--- |
| Utilización | | |
| Potencia | | |
| Clocks | | |

#### Cuestiones Parte B
1. **¿Qué cambia?** Suben drásticamente la potencia y la utilización. Los clocks pasan de estado de ahorro a máxima frecuencia.
2. **¿Por qué un kernel largo ayuda?** Porque permite que la herramienta de muestreo (que lee cada 1s aprox) capture el estado de carga antes de que termine.
3. **¿Si reduces N?** La ejecución sería tan rápida que `nvidia-smi` no llegaría a registrar el pico de actividad.

---

### 1.3. Parte C — Consulta programática (API CUDA)

**Código `query.cu` básico:**
```cpp
#include <stdio.h>
#include <cuda_runtime.h>

int main() {
    int ndev;
    cudaGetDeviceCount(&ndev);
    for (int d = 0; d < ndev; ++d) {
        cudaDeviceProp p;
        cudaGetDeviceProperties(&p, d);
        printf("Device %d: %s\n", d, p.name);
        printf("  Compute Capability: %d.%d\n", p.major, p.minor);
        printf("  SMs: %d\n", p.multiProcessorCount);
        printf("  Warp Size: %d\n", p.warpSize);
        printf("  Global Mem: %.2f GB\n", p.totalGlobalMem / (1024.0*1024.0*1024.0));
        printf("  Shared Mem/Block: %zu KB\n", p.sharedMemPerBlock / 1024);
        printf("  Regs/Block: %d\n", p.regsPerBlock);
        printf("  Max Threads/Block: %d\n", p.maxThreadsPerBlock);
        // Extras requeridos:
        printf("  L2 Cache: %d KB\n", p.l2CacheSize / 1024);
        printf("  Max Grid: [%d, %d, %d]\n", p.maxGridSize[0], p.maxGridSize[1], p.maxGridSize[2]);
    }
    return 0;
}
```