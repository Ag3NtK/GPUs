# Informe Laboratorio 1: Caracterización Experimental de la GPU
**Asignatura:** Programación en GPUs
**Nombre:** Javier Pedrajas Mendoza

---

## 1. Ejercicio 1 — Exploración y caracterización del dispositivo

### 1.1. Parte A — Inspección estática con `nvidia-smi`

Datos extraídos del comando base:
* **Modelo de GPU:** [NVIDIA GeForce RTX 3070 Laptop GPU]
* **Memoria Uso / Total:** [755MiB / 8192MiB]
* **Versión del Driver:** [591.59]
* **Utilización de GPU:** [1%]
* **Potencia (Draw/Cap):** [25W/140W]

#### Cuestiones Parte A
1. **¿La memoria es RAM o dedicada?** Es memoria VRAM dedicada de la GPU. La RAM del sistema se gestiona por la CPU y es independiente.
2. **¿Qué es GPU utilization?** Es el % de tiempo del último segundo en que hubo kernels activos. Puede ser baja con memoria llena si los datos están cargados pero no se están procesando (Memory bound).
3. **¿Por qué se muestra la potencia?** Para poder ver y controlar el límite térmico y energético (TDP). Es vital para evitar que el hardware se dañe y para dimensionar la fuente.

### Parte A.2 — Inspección detallada (`nvidia-smi -q`)
* **Capacidad y tipo de memoria:** [8192MiB: GDDR6]
* **Clocks Máximos:** [Graphics: 2100 MHz, SM: 2100 MHz, Memory: 7001 MHz, Video: 1950 MHz]
* **Enlace PCIe:** [Max: Gen 4 x16, Current: Gen 2 x16]

---

### 1.2. Parte B — Observación dinámica ([busy.cu](./busy.cu))

[Image of nvidia-smi output table showing GPU load and power increase]

| Campo | Idle | Ejecutando [busy.cu](./busy.cu) |
| :--- | :--- | :--- |
| Utilización | 0% | 100% |
| Potencia | 21W / 140W | 135W / 140W |
| Clocks | Core: 210 MHz , Mem: 810 MHz | Core: 1770 MHz , Mem: 7001 MHz|

#### Cuestiones Parte B
1. **¿Qué cambia?** Suben drásticamente la potencia y la utilización. Los clocks pasan de estado de ahorro a máxima frecuencia.
2. **¿Por qué un kernel largo ayuda?** Porque permite que la herramienta de muestreo observe el estado de la GPU antes de que termine.
3. **¿Si reduces N?** La ejecución sería tan rápida que `nvidia-smi` no llegaría a registrar el pico de actividad.

---

### 1.3. Parte C — Consulta programática (API CUDA)

## Análisis de Recursos de GPU ([query.cu](./query.cu))

### 1. ¿Qué significa `warpSize` y por qué aparece como propiedad explícita?
Es el grupo de **32 hilos** que la GPU ejecuta siempre al mismo tiempo (en bloque). y es explícito porque el programador necesita saber este número exacto para optimizar algoritmos de intercambio de datos y evitar que los hilos se "esperen" unos a otros.

### 2. ¿Qué recursos (a nivel de SM) sugieren `sharedMemPerBlock` y `regsPerBlock`?
* **Shared Mem:** Memoria rápida compartida entre hilos.
* **Regs:** Pequeños espacios de memoria ultra rápida para cada hilo.
* **Significado:** Si un programa usa demasiada memoria o demasiados registros, la GPU podrá ejecutar **menos bloques a la vez**, bajando el rendimiento.

### 3. ¿Qué información de [query.cu](./query.cu) será útil para razonar sobre ocupación?

La **ocupación** es el ratio entre los warps activos en un SM y el máximo de warps que el hardware permite. Los datos clave obtenidos son:

* **`maxThreadsPerMultiProcessor`**: El techo máximo de hilos que puede albergar un SM.
* **`regsPerBlock` y `sharedMemPerBlock`**: Permiten calcular cuántos bloques caben físicamente antes de agotar los recursos del SM.
* **`maxThreadsPerBlock`**: El límite de hilos por bloque (usualmente 1024), que condiciona la configuración del grid.
* **`multiProcessorCount`**: Crucial para dimensionar el problema global y asegurar que todos los SMs estén trabajando.

### 4. Referencia de Documentación Oficial

La descripción de la estructura `cudaDeviceProp` y la función `cudaGetDeviceProperties` se encuentra en la documentación oficial de NVIDIA:

* **Enlace:** [CUDA Runtime API - Device Management](https://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/html/group__CUDART__DEVICE_g5aa4f47938af8276f08074d09b7d520c.html)